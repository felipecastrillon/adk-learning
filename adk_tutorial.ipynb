{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Agent Development Kit (ADK) Tutorial\n",
    "\n",
    "**A hands-on guide to building AI agents with Google's ADK**\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Why ADK?](#1-why-adk) — What ADK is and why you'd use it\n",
    "2. [Setup](#2-setup) — Installation and project structure\n",
    "3. [Hello World Agent](#3-hello-world-agent) — Your first agent\n",
    "4. [CLI Interaction](#4-cli-interaction) — `adk run`, `adk web`, and Runner API\n",
    "5. [Agent Types](#5-agent-types) — Sequential, Parallel, and Loop agents\n",
    "6. [Tools](#6-tools) — Function tools, Google Search, BigQuery\n",
    "7. [Callbacks](#7-callbacks) — Guardrails, logging, and lifecycle hooks\n",
    "8. [Sessions, State, and Memory](#8-sessions-state-and-memory) — Context management\n",
    "9. [Clean Up](#9-clean-up) — Remove generated files\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- Google Cloud project with Vertex AI enabled\n",
    "- `gcloud auth application-default login` completed\n",
    "- Basic Python and async/await familiarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Explain what ADK is and how it compares to alternatives\n",
    "- Create and run ADK agents with tools\n",
    "- Compose agents using Sequential, Parallel, and Loop patterns\n",
    "- Use built-in tools like Google Search and BigQuery\n",
    "- Implement callbacks for guardrails and logging\n",
    "- Manage sessions, state, and memory across interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Why ADK?\n",
    "\n",
    "### What is the Agent Development Kit?\n",
    "\n",
    "Google's **Agent Development Kit (ADK)** is an open-source, code-first framework for building, evaluating, and deploying AI agents. Announced at Google Cloud NEXT 2025, it's the same framework that powers Google's own products like Agentspace and Customer Engagement Suite.\n",
    "\n",
    "**Core philosophy:** Agent development should feel like software development — version control, testing, modularity, and code review all apply.\n",
    "\n",
    "**Key features:**\n",
    "\n",
    "- **Code-first**: Agents are defined in Python (also TypeScript, Go, Java) — not dragged and dropped\n",
    "- **Model-agnostic**: Optimized for Gemini, but supports 100+ LLMs via LiteLLM (Claude, GPT-4, Llama, Mistral, etc.)\n",
    "- **Deployment-agnostic**: Run locally, on Cloud Run, GKE, Vertex AI Agent Engine, or any container host\n",
    "- **Full lifecycle**: Build → Interact → Evaluate → Deploy, all within one framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ADK Architecture Overview\n\n![ADK Architecture](images/image(6).png)\n\nThe ADK SDK sits between you (the developer) and your end users. It provides CLI tools for development, connects to AI models, and deploys to multiple targets — all from the same codebase."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADK vs. Alternatives\n",
    "\n",
    "| Dimension | ADK | LangGraph | CrewAI | DIY |\n",
    "|-----------|-----|-----------|--------|-----|\n",
    "| **Approach** | Hierarchical agent composition | Explicit directed graph | Role-based crews | Whatever you build |\n",
    "| **Languages** | Python, TS, Go, Java | Python, JS | Python only | Any |\n",
    "| **Multi-Agent** | Native (sub_agents, workflow agents) | Subgraphs | Native (Crews) | Build yourself |\n",
    "| **Tool Ecosystem** | Function, MCP, OpenAPI, AgentTool | LangChain tools | CrewAI + LangChain | Build yourself |\n",
    "| **Evaluation** | Built-in (`adk eval`) | Via LangSmith | Enterprise platform | Build yourself |\n",
    "| **Cloud Deploy** | Vertex AI, Cloud Run, GKE | LangSmith or self-hosted | Self-hosted | Build yourself |\n",
    "| **Best For** | Multi-agent systems with GCP | Complex stateful workflows | Team collaboration patterns | Unique requirements |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ADK vs. DIY\n\n![Why do you need a framework?](images/image(4).png)\n\n| Layer | DIY (Build Yourself) | ADK (Out of the Box) |\n|-------|---------------------|---------------------|\n| **LLM Integration** | Custom LLM wrapper | `Agent` + `LlmAgent` — model-agnostic |\n| **Tool Execution** | Custom tool engine | `FunctionTool` · `MCP` · `OpenAPI` — auto schema generation |\n| **Multi-Agent Orchestration** | Custom orchestration | `Sequential` · `Parallel` · `Loop` workflow agents |\n| **Session & State** | Custom session management | `Session` · `State` · `Memory` — multiple backends |\n| **Evaluation** | Custom eval framework | `adk eval` — built-in metrics |\n| **Deployment** | Custom infra | Cloud Run · GKE · Agent Engine — one-command deploy |\n| **Observability** | Custom logging | Cloud Trace · Monitoring — OpenTelemetry built-in |\n\nBuilding from scratch means implementing every layer yourself. ADK provides all of these out of the box."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Setup\n",
    "\n",
    "### Installing ADK\n",
    "\n",
    "ADK requires Python 3.10 or later. Install it with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the installation\n",
    "!pip show google-adk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ADK Project Structure\n\n![Project Structure](images/image(8).png)\n\nEvery ADK agent lives in a **directory** with three files:\n\n| File | Purpose |\n|------|--------|\n| `__init__.py` | Imports the agent module (`from . import agent`) |\n| `agent.py` | Defines `root_agent` — the entry point ADK discovers |\n| `.env` | API keys and project configuration |\n\nThe variable **must** be named `root_agent` — this is how ADK's CLI tools find your agent."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "ADK supports two backends for model access:\n",
    "\n",
    "**Vertex AI** (recommended for GCP users):\n",
    "```\n",
    "GOOGLE_GENAI_USE_VERTEXAI=TRUE\n",
    "GOOGLE_CLOUD_PROJECT=agentspace-testing-471714\n",
    "GOOGLE_CLOUD_LOCATION=us-central1\n",
    "```\n",
    "\n",
    "Requires: `gcloud auth application-default login`\n",
    "\n",
    "**Google AI Studio** (simpler, API key only):\n",
    "```\n",
    "GOOGLE_GENAI_USE_VERTEXAI=FALSE\n",
    "GOOGLE_API_KEY=your-api-key\n",
    "```\n",
    "\n",
    "This tutorial uses **Vertex AI**. Make sure your project has the Vertex AI API enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Hello World Agent\n",
    "\n",
    "Let's build our first agent. We'll create the standard ADK project structure using `%%writefile` magic so everything stays self-contained in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# Set environment variables for Vertex AI — required for programmatic Runner usage.\n# The .env files are only auto-loaded by CLI tools (adk run, adk web).\nos.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"TRUE\"\nos.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"agentspace-testing-471714\"\nos.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"\n\nos.makedirs(\"hello_agent\", exist_ok=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hello_agent/__init__.py\n",
    "from . import agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hello_agent/.env\n",
    "GOOGLE_GENAI_USE_VERTEXAI=TRUE\n",
    "GOOGLE_CLOUD_PROJECT=agentspace-testing-471714\n",
    "GOOGLE_CLOUD_LOCATION=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hello_agent/agent.py\n",
    "from google.adk.agents import Agent\n",
    "\n",
    "root_agent = Agent(\n",
    "    name=\"hello_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"A simple greeting agent.\",\n",
    "    instruction=\"You are a friendly assistant. Greet the user and answer their questions concisely.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent programmatically using Runner + InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai.types import Content, Part\n",
    "from hello_agent.agent import root_agent\n",
    "\n",
    "# Create the session service and runner\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(\n",
    "    agent=root_agent,\n",
    "    app_name=\"hello_app\",\n",
    "    session_service=session_service,\n",
    ")\n",
    "\n",
    "# Create a session\n",
    "session = await session_service.create_session(\n",
    "    app_name=\"hello_app\",\n",
    "    user_id=\"tutorial_user\",\n",
    ")\n",
    "\n",
    "# Send a message and collect the response\n",
    "message = Content(parts=[Part(text=\"Hello! What is ADK?\")], role=\"user\")\n",
    "\n",
    "response_text = \"\"\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\",\n",
    "    session_id=session.id,\n",
    "    new_message=message,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        response_text = event.content.parts[0].text\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Walkthrough\n",
    "\n",
    "Let's break down what just happened:\n",
    "\n",
    "1. **`Runner`** — The central orchestrator. It manages the event loop, coordinates the agent, LLM, tools, and services.\n",
    "\n",
    "2. **`InMemorySessionService`** — Stores session data in memory. Fine for development; use `DatabaseSessionService` or `VertexAiSessionService` for production.\n",
    "\n",
    "3. **`Content` and `Part`** — ADK's message format. `Content` is a container with a `role` (\"user\" or \"model\") and `Part` objects hold the actual data (text, function calls, etc.).\n",
    "\n",
    "4. **`runner.run_async()`** — Returns an async generator of `Event` objects. Each event represents something that happened during execution (LLM responses, tool calls, state changes). We filter for `is_final_response()` to get the agent's answer.\n",
    "\n",
    "5. **`Event.is_final_response()`** — Returns `True` when the event contains the agent's final text output (no pending tool calls or streaming chunks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation — the agent remembers context within the same session\n",
    "follow_up = Content(parts=[Part(text=\"Can you give me a one-sentence summary of what you just said?\")], role=\"user\")\n",
    "\n",
    "response_text = \"\"\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\",\n",
    "    session_id=session.id,  # Same session — context is preserved\n",
    "    new_message=follow_up,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        response_text = event.content.parts[0].text\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 4. CLI Interaction\n\nADK provides three ways to interact with your agent:\n\n| Mode | Command | Interface | Key Features |\n|------|---------|-----------|-------------|\n| **Terminal Chat** | `adk run` | CLI | Interactive or piped input; session save/resume |\n| **Browser Dev UI** | `adk web` | Browser | Chat + state inspector; events, traces, eval tabs |\n| **Programmatic** | `Runner` API | Python | `runner.run_async()`; full control in notebooks & apps |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adk run with piped input (non-interactive, works in notebooks)\n",
    "!echo \"What is 2 + 2?\" | adk run hello_agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import subprocess\nimport time\n\n# Launch adk web as a background process\nadk_web_process = subprocess.Popen(\n    [\n        \"adk\", \"web\", \".\",\n        \"--port\", \"8080\",\n        \"--session_service_uri\", \"memory://\",\n    ],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.PIPE,\n)\n\n# Give the server a moment to start\ntime.sleep(3)\n\nif adk_web_process.poll() is None:\n    print(\"adk web server is running!\")\n    print(\"Open the dev UI at: http://localhost:8080\")\nelse:\n    print(\"Failed to start adk web server.\")\n    _, stderr = adk_web_process.communicate()\n    print(f\"stderr: {stderr.decode()}\")"
  },
  {
   "cell_type": "markdown",
   "source": "### `adk web` — Browser Dev UI\n\nThe server above is now running and serving all agent subdirectories in the current working directory (including `hello_agent/` from Section 3).\n\nOpen **http://localhost:8080** in your browser to explore:\n\n- **Agent dropdown** — Select `hello_agent` (top left) to chat with it\n- **Chat interface** — Interactive conversation with your agent\n- **State inspector** — View and modify `session.state` in real time\n- **Event history** — See every event (LLM calls, tool invocations, state changes)\n- **Trace tab** — Detailed execution traces for debugging\n\nWhen you're done exploring, run the next cell to stop the server.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Stop the adk web server\nif adk_web_process.poll() is None:\n    adk_web_process.terminate()\n    adk_web_process.wait(timeout=5)\n    print(\"adk web server stopped.\")\nelse:\n    print(\"adk web server was not running.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `adk api_server` — REST API\n",
    "\n",
    "`adk api_server` starts a FastAPI server with Swagger docs at `/docs`. Key endpoints:\n",
    "\n",
    "| Method | Path | Description |\n",
    "|--------|------|-------------|\n",
    "| `GET` | `/list-apps` | List available agents |\n",
    "| `POST` | `/run` | Run agent (single JSON response) |\n",
    "| `POST` | `/run_sse` | Run agent (Server-Sent Events stream) |\n",
    "\n",
    "This is useful for integrating agents into web applications or microservices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 5. Agent Types\n\nWe already built an `LlmAgent` (aliased as `Agent`) in Section 3. Now let's look at the **workflow agents** that provide deterministic orchestration without LLM routing decisions.\n\n![The Core of ADK — The Agent](images/image(1).png)\n\n| Agent Class | Parent | Description | Key Features |\n|------------|--------|-------------|-------------|\n| **`LlmAgent`** (`Agent`) | `BaseAgent` | LLM-powered reasoning | Dynamic tool use, sub-agent delegation |\n| **`SequentialAgent`** | `BaseAgent` | Executes sub-agents in order | Shared state via `output_key`, template variable passing |\n| **`ParallelAgent`** | `BaseAgent` | Concurrent execution | Independent conversation history, shared `session.state` |\n| **`LoopAgent`** | `BaseAgent` | Iterative refinement | `max_iterations` limit, `escalate` to exit |\n| Custom Agents | `BaseAgent` | Extend `BaseAgent` | Whatever you need |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequentialAgent\n",
    "\n",
    "Executes sub-agents **in order**, one after another. Data flows between steps via `output_key` and template variables:\n",
    "\n",
    "1. Agent A runs, its response is saved to `session.state[\"result_a\"]` via `output_key=\"result_a\"`\n",
    "2. Agent B's instruction references `{result_a}` — ADK resolves this from session state before sending to the LLM\n",
    "\n",
    "```python\n",
    "pipeline = SequentialAgent(\n",
    "    name=\"Pipeline\",\n",
    "    sub_agents=[agent_a, agent_b, agent_c],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParallelAgent\n",
    "\n",
    "Executes all sub-agents **concurrently**. Each branch has independent conversation history, but they share `session.state`. Event ordering may be non-deterministic.\n",
    "\n",
    "```python\n",
    "parallel = ParallelAgent(\n",
    "    name=\"ParallelResearch\",\n",
    "    sub_agents=[researcher_a, researcher_b],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoopAgent\n",
    "\n",
    "Repeatedly executes sub-agents in sequence until a termination condition is met:\n",
    "\n",
    "1. `max_iterations` parameter (hard limit)\n",
    "2. A sub-agent calls `tool_context.actions.escalate = True` to break out\n",
    "\n",
    "```python\n",
    "loop = LoopAgent(\n",
    "    name=\"RefinementLoop\",\n",
    "    sub_agents=[critic, refiner],\n",
    "    max_iterations=5,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: ParallelAgent + SequentialAgent composition\n",
    "# Two researchers run in parallel, then a synthesizer combines their results.\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "# Two researchers that run concurrently\n",
    "researcher_a = Agent(\n",
    "    name=\"RenewableResearcher\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=\"Write a short 2-3 sentence overview of recent advances in renewable energy.\",\n",
    "    output_key=\"renewable_result\",\n",
    ")\n",
    "\n",
    "researcher_b = Agent(\n",
    "    name=\"EVResearcher\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=\"Write a short 2-3 sentence overview of recent advances in electric vehicles.\",\n",
    "    output_key=\"ev_result\",\n",
    ")\n",
    "\n",
    "parallel_research = ParallelAgent(\n",
    "    name=\"ParallelResearch\",\n",
    "    sub_agents=[researcher_a, researcher_b],\n",
    ")\n",
    "\n",
    "# Synthesizer reads both results via template variables\n",
    "synthesizer = Agent(\n",
    "    name=\"Synthesizer\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=(\n",
    "        \"Combine these two research summaries into a single coherent paragraph \"\n",
    "        \"about the intersection of clean energy and transportation:\\n\\n\"\n",
    "        \"Renewable Energy: {renewable_result}\\n\\n\"\n",
    "        \"Electric Vehicles: {ev_result}\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sequential wraps: parallel stage → synthesizer\n",
    "workflow = SequentialAgent(\n",
    "    name=\"ResearchWorkflow\",\n",
    "    sub_agents=[parallel_research, synthesizer],\n",
    ")\n",
    "\n",
    "# Run the workflow\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=workflow, app_name=\"research_app\", session_service=session_service)\n",
    "session = await session_service.create_session(app_name=\"research_app\", user_id=\"tutorial_user\")\n",
    "\n",
    "message = Content(parts=[Part(text=\"Research clean energy and EVs.\")], role=\"user\")\n",
    "\n",
    "response_text = \"\"\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\",\n",
    "    session_id=session.id,\n",
    "    new_message=message,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        response_text = event.content.parts[0].text\n",
    "\n",
    "print(\"=== Synthesized Result ===\")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Which Agent Type\n",
    "\n",
    "| Agent Type | Use When... | Example |\n",
    "|------------|------------|--------|\n",
    "| **LlmAgent** | You need LLM reasoning, tool use, or dynamic decisions | Chatbots, Q&A, tool-calling agents |\n",
    "| **SequentialAgent** | Steps must happen in order, each building on the previous | Write → Review → Refactor pipeline |\n",
    "| **ParallelAgent** | Tasks are independent and can run concurrently | Multi-source research, parallel API calls |\n",
    "| **LoopAgent** | Iterative refinement until quality threshold is met | Draft → Critique → Revise loops |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. Tools\n\nTools give agents the ability to take actions and access external data. ADK has one of the most extensive tool ecosystems of any agent framework.\n\n![Tools in ADK](images/image(3).png)\n\n| Category | Tool | Description |\n|----------|------|-------------|\n| **Function Tools** | `FunctionTool` | Auto schema from docstrings + type hints |\n| | `LongRunningFunctionTool` | Async ops & human-in-the-loop |\n| **Agent-as-Tool** | `AgentTool` | Wrap any agent as a callable tool; cross-framework interop |\n| **Protocol Tools** | `MCPToolset` | Connect to MCP servers (Stdio & SSE transport) |\n| | `OpenAPIToolset` | Auto-generate tools from OpenAPI specs |\n| **Built-in Google** | `google_search` | Gemini 2+ only |\n| | `BigQueryToolset` | 7 built-in tools: SQL, forecast, insights |\n| | `VertexAiSearchTool` | Private data stores |\n| | `BuiltInCodeExecutor` | Sandboxed Python |\n| **Runtime Access** | `ToolContext` | `state`, `actions`, `artifacts`, `memory`, `auth credentials` |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Tools\n",
    "\n",
    "Any regular Python function can become a tool. ADK inspects the function's **name**, **docstring**, **type hints**, and **defaults** to auto-generate a schema for the LLM.\n",
    "\n",
    "Rules:\n",
    "- Parameters without defaults are **required**; with defaults are **optional**\n",
    "- Return a `dict` with a `\"status\"` key for best results\n",
    "- Docstrings and type hints are critical — they tell the LLM what the tool does and how to call it\n",
    "- Add `tool_context: ToolContext` as a parameter to access runtime state, actions, artifacts, and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function tool example\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The city name to get weather for.\n",
    "    \"\"\"\n",
    "    # Simulated weather data\n",
    "    weather_data = {\n",
    "        \"new york\": {\"temp\": \"22°C\", \"condition\": \"Sunny\"},\n",
    "        \"london\": {\"temp\": \"15°C\", \"condition\": \"Cloudy\"},\n",
    "        \"tokyo\": {\"temp\": \"28°C\", \"condition\": \"Humid\"},\n",
    "    }\n",
    "    city_lower = city.lower()\n",
    "    if city_lower in weather_data:\n",
    "        data = weather_data[city_lower]\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"report\": f\"The weather in {city} is {data['condition']}, {data['temp']}.\",\n",
    "        }\n",
    "    return {\n",
    "        \"status\": \"error\",\n",
    "        \"error_message\": f\"Weather data for '{city}' is not available.\",\n",
    "    }\n",
    "\n",
    "\n",
    "# Create an agent with the tool\n",
    "weather_agent = Agent(\n",
    "    name=\"weather_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Agent that answers weather questions.\",\n",
    "    instruction=\"You are a weather assistant. Use the get_weather tool to answer questions about weather.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "# Run it\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=weather_agent, app_name=\"weather_app\", session_service=session_service)\n",
    "session = await session_service.create_session(app_name=\"weather_app\", user_id=\"tutorial_user\")\n",
    "\n",
    "message = Content(parts=[Part(text=\"What's the weather like in Tokyo?\")], role=\"user\")\n",
    "\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\",\n",
    "    session_id=session.id,\n",
    "    new_message=message,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        print(event.content.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Tools\n",
    "\n",
    "ADK ships with several built-in tools for Google Cloud services:\n",
    "\n",
    "**Google Search** (`google_search`):\n",
    "- Import: `from google.adk.tools import google_search`\n",
    "- Requires Gemini 2+ models\n",
    "- **Single-tool limitation**: Google Search cannot be combined with other tools in a single agent. Workaround: use a sub-agent pattern where a dedicated search agent handles Google Search, and the parent agent delegates to it.\n",
    "\n",
    "**BigQuery** (`BigQueryToolset`):\n",
    "- Import: `from google.adk.tools import BigQueryToolset`\n",
    "- Provides 7 built-in tools: SQL queries, forecasting, insights, and more\n",
    "- Operates on your GCP project's BigQuery datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Google Search agent — must be the only tool on the agent\nimport os\nos.makedirs(\"tools_agent\", exist_ok=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tools_agent/__init__.py\n",
    "from . import agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tools_agent/.env\n",
    "GOOGLE_GENAI_USE_VERTEXAI=TRUE\n",
    "GOOGLE_CLOUD_PROJECT=agentspace-testing-471714\n",
    "GOOGLE_CLOUD_LOCATION=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%writefile tools_agent/agent.py\nfrom google.adk.agents import Agent\nfrom google.adk.tools import google_search\nfrom google.adk.tools.bigquery.bigquery_toolset import BigQueryToolset\n\n# Google Search agent — google_search MUST be the only tool (API limitation)\nsearch_agent = Agent(\n    name=\"search_agent\",\n    model=\"gemini-2.5-flash\",\n    description=\"Searches the web for information.\",\n    instruction=\"You are a web search specialist. Use Google Search to find information and provide concise answers.\",\n    tools=[google_search],\n)\n\n# BigQuery agent — separate agent since google_search can't mix with other tools\nbigquery_agent = Agent(\n    name=\"bigquery_agent\",\n    model=\"gemini-2.5-flash\",\n    description=\"Queries BigQuery datasets.\",\n    instruction=(\n        \"You are a data analyst assistant with access to BigQuery.\\n\"\n        \"The public dataset `bigquery-public-data.samples.shakespeare` contains \"\n        \"Shakespeare's works with columns: word, word_count, corpus, corpus_date.\\n\"\n        \"Always explain your findings clearly.\"\n    ),\n    tools=[BigQueryToolset()],\n)\n\n# Expose search_agent as the default for CLI usage\nroot_agent = search_agent"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Demo 1: Google Search\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai.types import Content, Part\nfrom tools_agent.agent import search_agent, bigquery_agent\n\nprint(\"=== Google Search ===\")\nsession_service = InMemorySessionService()\nrunner = Runner(agent=search_agent, app_name=\"search_app\", session_service=session_service)\nsession = await session_service.create_session(app_name=\"search_app\", user_id=\"tutorial_user\")\n\nmessage = Content(parts=[Part(text=\"What is Shakespeare's most famous play?\")], role=\"user\")\nasync for event in runner.run_async(\n    user_id=\"tutorial_user\", session_id=session.id, new_message=message,\n):\n    if event.is_final_response() and event.content and event.content.parts:\n        print(event.content.parts[0].text)\n\n# Demo 2: BigQuery\nprint(\"\\n=== BigQuery ===\")\nsession_service = InMemorySessionService()\nrunner = Runner(agent=bigquery_agent, app_name=\"bq_app\", session_service=session_service)\nsession = await session_service.create_session(app_name=\"bq_app\", user_id=\"tutorial_user\")\n\nmessage = Content(\n    parts=[Part(text=(\n        \"Count how many distinct works (corpus values) are in the \"\n        \"bigquery-public-data.samples.shakespeare dataset.\"\n    ))],\n    role=\"user\",\n)\nasync for event in runner.run_async(\n    user_id=\"tutorial_user\", session_id=session.id, new_message=message,\n):\n    if event.is_final_response() and event.content and event.content.parts:\n        print(event.content.parts[0].text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Tool Types\n",
    "\n",
    "| Tool Type | Class | Use Case |\n",
    "|-----------|-------|----------|\n",
    "| **Function Tool** | `FunctionTool` | Any Python function — auto-generates schema from docstring + type hints |\n",
    "| **Long-Running** | `LongRunningFunctionTool` | Async operations, human-in-the-loop approval workflows |\n",
    "| **Agent-as-Tool** | `AgentTool` | Wrap any agent as a callable tool — enables cross-framework interop |\n",
    "| **MCP Tools** | `McpToolset` | Connect to Model Context Protocol servers (Stdio or SSE transport) |\n",
    "| **OpenAPI Tools** | `OpenAPIToolset` | Auto-generate tools from an OpenAPI spec (JSON or YAML) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToolContext\n",
    "\n",
    "Any tool function can accept a `tool_context: ToolContext` parameter for runtime access:\n",
    "\n",
    "| Property | Description |\n",
    "|----------|-------------|\n",
    "| `tool_context.state` | Read/write session state (supports prefix scoping) |\n",
    "| `tool_context.actions` | Control flow — `escalate`, `transfer_to_agent`, `skip_summarization` |\n",
    "| `tool_context.save_artifact(name, part)` | Save binary data (files, images) |\n",
    "| `tool_context.load_artifact(name)` | Load previously saved artifacts |\n",
    "| `tool_context.search_memory(query)` | Query the memory service |\n",
    "| `tool_context.function_call_id` | ID of the current function call |\n",
    "\n",
    "```python\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "def my_tool(query: str, tool_context: ToolContext) -> dict:\n",
    "    tool_context.state[\"temp:last_query\"] = query\n",
    "    tool_context.state[\"user:query_count\"] = tool_context.state.get(\"user:query_count\", 0) + 1\n",
    "    return {\"status\": \"success\", \"result\": \"...\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 7. Callbacks\n\nCallbacks hook into an agent's execution at predefined points. They let you observe, modify, or override behavior — without changing the agent's core logic.\n\n### Callback Lifecycle\n\nThe execution flow follows this sequence:\n\n| Step | Event | Callback | Skip / Override |\n|------|-------|----------|-----------------|\n| 1 | User message received | `before_agent_callback` | Return `Content` to skip agent entirely |\n| 2 | Prompt sent to LLM | `before_model_callback` | Return `LlmResponse` to skip LLM call |\n| 3 | LLM response received | `after_model_callback` | Return `LlmResponse` to replace response |\n| 4 | Tool call initiated | `before_tool_callback` | Return `dict` to skip tool execution |\n| 5 | Tool result returned | `after_tool_callback` | Return `dict` to replace tool result |\n| 6 | Agent response finalized | `after_agent_callback` | Return `Content` to replace final output |\n\n**Pattern:** Return `None` to proceed normally, or return a value to **override** the default behavior."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Six Callbacks\n",
    "\n",
    "| Callback | Parameters | Return `None` | Return a Value |\n",
    "|----------|-----------|--------------|----------------|\n",
    "| `before_agent_callback` | `CallbackContext` | Agent runs normally | `Content` — skip the agent entirely |\n",
    "| `after_agent_callback` | `CallbackContext` | Use agent's output | `Content` — replace the output |\n",
    "| `before_model_callback` | `CallbackContext`, `LlmRequest` | LLM call proceeds | `LlmResponse` — skip the LLM call |\n",
    "| `after_model_callback` | `CallbackContext`, `LlmResponse` | Use LLM response | `LlmResponse` — replace the response |\n",
    "| `before_tool_callback` | `BaseTool`, `args: dict`, `ToolContext` | Tool runs normally | `dict` — skip the tool |\n",
    "| `after_tool_callback` | `BaseTool`, `args: dict`, `ToolContext`, `tool_response: dict` | Use tool result | `dict` — replace the result |\n",
    "\n",
    "The pattern is simple: return `None` to proceed normally, or return a value to **override** the default behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardrail callback: before_model_callback blocks forbidden keywords\n",
    "import os\n",
    "os.makedirs(\"callback_agent\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile callback_agent/__init__.py\n",
    "from . import agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile callback_agent/.env\n",
    "GOOGLE_GENAI_USE_VERTEXAI=TRUE\n",
    "GOOGLE_CLOUD_PROJECT=agentspace-testing-471714\n",
    "GOOGLE_CLOUD_LOCATION=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile callback_agent/agent.py\n",
    "from typing import Optional\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "from google.adk.models import LlmRequest, LlmResponse\n",
    "from google.adk.tools.base_tool import BaseTool\n",
    "from google.adk.tools import ToolContext\n",
    "from google.genai import types\n",
    "\n",
    "FORBIDDEN_WORDS = [\"hack\", \"exploit\", \"bypass\"]\n",
    "\n",
    "\n",
    "def guardrail_before_model(\n",
    "    callback_context: CallbackContext,\n",
    "    llm_request: LlmRequest,\n",
    ") -> Optional[LlmResponse]:\n",
    "    \"\"\"Block requests containing forbidden keywords.\"\"\"\n",
    "    # Safely extract text from the last user message\n",
    "    user_text = \"\"\n",
    "    for content in reversed(llm_request.contents):\n",
    "        if content.role == \"user\":\n",
    "            for part in content.parts:\n",
    "                if part.text:\n",
    "                    user_text = part.text.lower()\n",
    "                    break\n",
    "            if user_text:\n",
    "                break\n",
    "    for word in FORBIDDEN_WORDS:\n",
    "        if word in user_text:\n",
    "            print(f\"[GUARDRAIL] Blocked request containing '{word}'\")\n",
    "            return LlmResponse(\n",
    "                content=types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part(text=\"I cannot process requests containing restricted terms.\")],\n",
    "                )\n",
    "            )\n",
    "    return None  # Proceed normally\n",
    "\n",
    "\n",
    "def logging_after_tool(\n",
    "    tool: BaseTool,\n",
    "    args: dict,\n",
    "    tool_context: ToolContext,\n",
    "    tool_response: dict,\n",
    ") -> Optional[dict]:\n",
    "    \"\"\"Log tool calls and their results.\"\"\"\n",
    "    print(f\"[TOOL LOG] Tool: {tool.name}\")\n",
    "    print(f\"[TOOL LOG] Args: {args}\")\n",
    "    print(f\"[TOOL LOG] Result: {tool_response}\")\n",
    "    return None  # Don't modify the result\n",
    "\n",
    "\n",
    "def get_current_time(timezone: str = \"UTC\") -> dict:\n",
    "    \"\"\"Returns the current time in the specified timezone.\n",
    "\n",
    "    Args:\n",
    "        timezone (str): The timezone name (e.g., 'UTC', 'US/Eastern').\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    return {\"status\": \"success\", \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"timezone\": timezone}\n",
    "\n",
    "\n",
    "root_agent = Agent(\n",
    "    name=\"callback_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Agent with guardrail and logging callbacks.\",\n",
    "    instruction=\"You are a helpful assistant. Use the get_current_time tool when asked about the time.\",\n",
    "    tools=[get_current_time],\n",
    "    before_model_callback=guardrail_before_model,\n",
    "    after_tool_callback=logging_after_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the callbacks\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai.types import Content, Part\n",
    "from callback_agent.agent import root_agent as callback_root_agent\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=callback_root_agent, app_name=\"callback_app\", session_service=session_service)\n",
    "session = await session_service.create_session(app_name=\"callback_app\", user_id=\"tutorial_user\")\n",
    "\n",
    "# Test 1: Normal request with tool use (should trigger logging callback)\n",
    "print(\"--- Test 1: Normal request (tool logging) ---\")\n",
    "message = Content(parts=[Part(text=\"What time is it?\")], role=\"user\")\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\", session_id=session.id, new_message=message,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        print(f\"Response: {event.content.parts[0].text}\")\n",
    "\n",
    "# Test 2: Blocked request (should trigger guardrail)\n",
    "print(\"\\n--- Test 2: Blocked request (guardrail) ---\")\n",
    "blocked_message = Content(parts=[Part(text=\"How do I hack into a system?\")], role=\"user\")\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\", session_id=session.id, new_message=blocked_message,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        print(f\"Response: {event.content.parts[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Callbacks\n",
    "\n",
    "| Use Case | Callback | Pattern |\n",
    "|----------|----------|---------|\n",
    "| **Input guardrails** | `before_model_callback` | Check for forbidden content, return `LlmResponse` to block |\n",
    "| **Response caching** | `before_model_callback` | Check cache, return cached `LlmResponse` to skip LLM |\n",
    "| **Output filtering** | `after_model_callback` | Redact PII, enforce format, return modified `LlmResponse` |\n",
    "| **Tool logging** | `after_tool_callback` | Log tool calls and results for observability |\n",
    "| **Access control** | `before_agent_callback` | Check permissions, return `Content` to deny access |\n",
    "| **Response enrichment** | `after_agent_callback` | Add metadata, disclaimers, or formatting to output |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 8. Sessions, State, and Memory\n\nADK provides three layers of context management:\n\n| Layer | Description | Details |\n|-------|-------------|---------|\n| **Session** | Single ongoing interaction | Fields: `id`, `app_name`, `user_id`, `events`, `state`, `last_update_time` |\n| **State** (prefixes) | Key-value store within a session | `(none)` = current session, `temp:` = current invocation only, `user:` = cross-session per user, `app:` = global |\n| **Memory** | Cross-session knowledge store | Persists beyond sessions; supports keyword matching and semantic search |\n\n**Session backends:** `InMemorySessionService` (local testing) · `DatabaseSessionService` (SQLite/PostgreSQL) · `VertexAiSessionService` (managed production)\n\n**Memory backends:** `InMemoryMemoryService` (keyword matching, prototyping) · `VertexAiMemoryBankService` (semantic search, production)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions\n",
    "\n",
    "A **Session** represents a single ongoing interaction (conversation). Key fields:\n",
    "\n",
    "| Field | Description |\n",
    "|-------|-------------|\n",
    "| `id` | Unique conversation identifier |\n",
    "| `app_name` | Which agent application owns this session |\n",
    "| `user_id` | Links to a particular user |\n",
    "| `events` | Chronological sequence of all interactions |\n",
    "| `state` | Key-value store for conversation data |\n",
    "\n",
    "**SessionService backends:**\n",
    "\n",
    "| Service | Backend | Use Case |\n",
    "|---------|---------|----------|\n",
    "| `InMemorySessionService` | In-memory | Local testing (lost on restart) |\n",
    "| `DatabaseSessionService` | SQLite, PostgreSQL, MySQL | Self-hosted production |\n",
    "| `VertexAiSessionService` | Vertex AI Agent Engine | Managed GCP production |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session demo: create a session with initial state, run agent, inspect results\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "session_agent = Agent(\n",
    "    name=\"session_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=\"You are a helpful assistant. The user's name is {user_name}. Greet them by name.\",\n",
    ")\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=session_agent, app_name=\"session_app\", session_service=session_service)\n",
    "\n",
    "# Create session with initial state\n",
    "session = await session_service.create_session(\n",
    "    app_name=\"session_app\",\n",
    "    user_id=\"tutorial_user\",\n",
    "    state={\"user_name\": \"Alice\"},  # Initial state\n",
    ")\n",
    "\n",
    "message = Content(parts=[Part(text=\"Hi there!\")], role=\"user\")\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\", session_id=session.id, new_message=message,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        print(f\"Agent: {event.content.parts[0].text}\")\n",
    "\n",
    "# Inspect session state and events\n",
    "updated_session = await session_service.get_session(\n",
    "    app_name=\"session_app\", user_id=\"tutorial_user\", session_id=session.id,\n",
    ")\n",
    "print(f\"\\nSession ID: {updated_session.id}\")\n",
    "print(f\"State: {dict(updated_session.state)}\")\n",
    "print(f\"Number of events: {len(updated_session.events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State\n",
    "\n",
    "`session.state` is a key-value dictionary with **prefix-based scoping**:\n",
    "\n",
    "| Prefix | Scope | Persistence |\n",
    "|--------|-------|-------------|\n",
    "| *(none)* | Current session only | Session lifetime |\n",
    "| `temp:` | Current invocation only | **Never** persisted |\n",
    "| `user:` | All sessions for that user | With DB/Vertex services |\n",
    "| `app:` | All users and sessions | With DB/Vertex services |\n",
    "\n",
    "**Three ways to write state:**\n",
    "\n",
    "1. **`output_key`** — Agent's response auto-saved: `Agent(output_key=\"last_response\", ...)`\n",
    "2. **`ToolContext.state`** — Recommended in tool functions: `tool_context.state[\"key\"] = value`\n",
    "3. **`EventActions.state_delta`** — Low-level, via event actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State demo: tool writes to different prefixes, output_key auto-save\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import ToolContext\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "\n",
    "def track_query(query: str, tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Tracks user queries and updates state with different prefixes.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's search query.\n",
    "    \"\"\"\n",
    "    # temp: prefix — only lasts this invocation\n",
    "    tool_context.state[\"temp:current_query\"] = query\n",
    "\n",
    "    # user: prefix — persists across sessions (with DB/Vertex services)\n",
    "    count = tool_context.state.get(\"user:total_queries\", 0)\n",
    "    tool_context.state[\"user:total_queries\"] = count + 1\n",
    "\n",
    "    # No prefix — persists within this session\n",
    "    tool_context.state[\"last_query\"] = query\n",
    "\n",
    "    return {\"status\": \"success\", \"message\": f\"Tracked query: {query}\"}\n",
    "\n",
    "\n",
    "state_agent = Agent(\n",
    "    name=\"state_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=\"You track queries. When the user asks something, use track_query first, then answer.\",\n",
    "    tools=[track_query],\n",
    "    output_key=\"last_response\",  # Auto-save response to state\n",
    ")\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=state_agent, app_name=\"state_app\", session_service=session_service)\n",
    "session = await session_service.create_session(app_name=\"state_app\", user_id=\"tutorial_user\")\n",
    "\n",
    "message = Content(parts=[Part(text=\"Track a query about 'Python async patterns'\")], role=\"user\")\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\", session_id=session.id, new_message=message,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        print(f\"Agent: {event.content.parts[0].text}\")\n",
    "\n",
    "# Inspect state after\n",
    "updated_session = await session_service.get_session(\n",
    "    app_name=\"state_app\", user_id=\"tutorial_user\", session_id=session.id,\n",
    ")\n",
    "print(\"\\n--- Session State ---\")\n",
    "for key, value in sorted(updated_session.state.items()):\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "**Memory** is long-term knowledge that persists **across sessions**. While State is per-session, Memory stores extracted facts that any future session can retrieve.\n",
    "\n",
    "| Service | Backend | Features |\n",
    "|---------|---------|----------|\n",
    "| `InMemoryMemoryService` | In-memory | Basic keyword matching, for prototyping |\n",
    "| `VertexAiMemoryBankService` | Vertex AI | LLM-powered extraction, semantic search |\n",
    "\n",
    "**Workflow:**\n",
    "1. User interacts with agent → session events captured\n",
    "2. Call `memory_service.add_session_to_memory(session)` → extracts and stores key facts\n",
    "3. In a later session, agent queries with `search_memory(query)` → retrieves relevant memories\n",
    "\n",
    "**Built-in memory tools:**\n",
    "- `PreloadMemoryTool` — automatically retrieves relevant memories at the start of each turn\n",
    "- `LoadMemoryTool` — retrieves on-demand when the agent decides to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory demo: Session A stores info → add to memory → Session B retrieves it\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "from google.adk.tools.preload_memory_tool import PreloadMemoryTool\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "memory_service = InMemoryMemoryService()\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Agent with memory retrieval\n",
    "memory_agent = Agent(\n",
    "    name=\"memory_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=(\n",
    "        \"You are a helpful assistant with memory. \"\n",
    "        \"Use information from memory to provide personalized responses. \"\n",
    "        \"If memory has relevant info, mention it.\"\n",
    "    ),\n",
    "    tools=[PreloadMemoryTool()],\n",
    ")\n",
    "\n",
    "runner = Runner(\n",
    "    agent=memory_agent,\n",
    "    app_name=\"memory_app\",\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "# --- Session A: Store information ---\n",
    "print(\"=== Session A: Storing information ===\")\n",
    "session_a = await session_service.create_session(\n",
    "    app_name=\"memory_app\", user_id=\"tutorial_user\",\n",
    ")\n",
    "\n",
    "msg_a = Content(parts=[Part(text=\"My favorite programming language is Python and I work at Acme Corp.\")], role=\"user\")\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\", session_id=session_a.id, new_message=msg_a,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        print(f\"Agent: {event.content.parts[0].text}\")\n",
    "\n",
    "# Add session A to memory\n",
    "updated_session_a = await session_service.get_session(\n",
    "    app_name=\"memory_app\", user_id=\"tutorial_user\", session_id=session_a.id,\n",
    ")\n",
    "await memory_service.add_session_to_memory(updated_session_a)\n",
    "print(\"\\n[Memory updated with Session A data]\")\n",
    "\n",
    "# --- Session B: Retrieve from memory ---\n",
    "print(\"\\n=== Session B: Retrieving from memory ===\")\n",
    "session_b = await session_service.create_session(\n",
    "    app_name=\"memory_app\", user_id=\"tutorial_user\",\n",
    ")\n",
    "\n",
    "msg_b = Content(parts=[Part(text=\"What do you know about me?\")], role=\"user\")\n",
    "async for event in runner.run_async(\n",
    "    user_id=\"tutorial_user\", session_id=session_b.id, new_message=msg_b,\n",
    "):\n",
    "    if event.is_final_response() and event.content and event.content.parts:\n",
    "        print(f\"Agent: {event.content.parts[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Clean Up\n",
    "\n",
    "Remove the agent directories created during this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import shutil\n\n# Stop adk web server if still running\ntry:\n    if adk_web_process.poll() is None:\n        adk_web_process.terminate()\n        adk_web_process.wait(timeout=5)\n        print(\"Stopped adk web server.\")\nexcept NameError:\n    pass  # adk_web_process was never created\n\nfor agent_dir in [\"hello_agent\", \"tools_agent\", \"callback_agent\"]:\n    if os.path.exists(agent_dir):\n        shutil.rmtree(agent_dir)\n        print(f\"Removed {agent_dir}/\")\n    else:\n        print(f\"{agent_dir}/ not found (already removed)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### What's Next?\n\n![Key Takeaways](images/image(2).png)\n\nYou've covered the core of ADK. Here are suggested next steps:\n\n- **Deploy your agent**: Try `adk deploy cloud_run` to ship to Google Cloud Run\n- **Add evaluation**: Create `.test.json` files and run `adk eval` to measure quality\n- **Explore MCP tools**: Connect to external services via the Model Context Protocol\n- **Use Vertex AI Agent Engine**: Deploy to the fully managed service for production\n- **Try multi-model agents**: Use `LiteLlm` to combine Gemini with Claude, GPT-4, or local models\n\n**Resources:**\n\n- [ADK Documentation](https://google.github.io/adk-docs/)\n- [ADK GitHub (Python)](https://github.com/google/adk-python)\n- [ADK Quickstart](https://google.github.io/adk-docs/get-started/quickstart/)\n- [Vertex AI Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "- **Google Agent Development Kit** — [google.github.io/adk-docs](https://google.github.io/adk-docs/)\n",
    "- **Gemini API** — [ai.google.dev](https://ai.google.dev/)\n",
    "- Notebook generated with assistance from Claude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adk-tutorial",
   "language": "python",
   "name": "adk-tutorial"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}